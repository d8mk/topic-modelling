{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "\n",
    "\n",
    "def downxml():\n",
    "    if os.path.isfile('/Users/neele/Downloads/uscode.zip') == 1:\n",
    "        print(\"File Already Present!\")\n",
    "    else:\n",
    "        url = 'https://uscode.house.gov/download/releasepoints/us/pl/117/327not263not286/xml_usc26@117-327not263not286.zip'\n",
    "        urllib.request.urlretrieve(url, '/Users/neele/Downloads/uscode.zip')\n",
    "\n",
    "    zf = ZipFile('/Users/neele/Downloads/uscode.zip', 'r')\n",
    "    zf.extractall('/Users/neele/Downloads/')\n",
    "    zf.close()\n",
    "    print('File Extract Success!')\n",
    "\n",
    "downxml()\n",
    "\n",
    "tree = etree.parse('/Users/neele/Downloads/usc26.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "root.remove(root[0])\n",
    "print(root[0].tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_dict = {'ns': root.nsmap[None]}\n",
    "notes = root.xpath(\"//ns:notes\",namespaces = ns_dict)\n",
    "toc = root.xpath(\"//ns:toc\",namespaces = ns_dict)\n",
    "note = root.xpath(\"//ns:note\",namespaces = ns_dict)\n",
    "srcrd = root.xpath(\"//ns:sourceCredit\",namespaces = ns_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[node.getparent().remove(node) for node in note]\n",
    "[node.getparent().remove(node) for node in notes]\n",
    "[node.getparent().remove(node) for node in toc]\n",
    "[node.getparent().remove(node) for node in srcrd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = root.findall(\".//ns:section\",namespaces = ns_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([node.getparent() for node in nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs=''\n",
    "for node in nodes:\n",
    "    text = ' '.join(node.itertext()).strip()\n",
    "    text=text+'//////'\n",
    "    secs = secs+text\n",
    "\n",
    "sep_pattern = r\"\\s*//////\\s*\"\n",
    "\n",
    "\n",
    "with open('secs_regex1.txt', 'w',encoding='utf-8') as f:\n",
    "\n",
    "    for line in secs:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secs_regex1.txt', 'r',encoding='utf-8') as f:\n",
    "    fintxt = f.read()\n",
    "\n",
    "rows = fintxt.split(\"//////\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snum(row):\n",
    "    pattern = r'\\d.*?(?=\\.)'\n",
    "    match = re.search(pattern, row)\n",
    "    if match:\n",
    "       return (match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(x):\n",
    "    dot_index = x.find(\".\")\n",
    "    result = x[dot_index + 1:]\n",
    "    return result\n",
    "\n",
    "data = {'Title':['26' for row in rows],'Section': [get_snum(row) for row in rows], 'Content': [get_text(row) for row in rows]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('finsec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf=df.copy()\n",
    "repealed_rows = rdf[rdf['Content'].str.contains('Repealed\\.  Pub\\.') & (rdf['Content'].str.len() <= 100)].index.tolist()\n",
    "\n",
    "print(repealed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = rdf.drop(repealed_rows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def clean_text(x):\n",
    "  x = str(x)\n",
    "  x = x.lower()\n",
    "  x = re.sub(r'#[A-Za-z0-9]*', ' ', x)\n",
    "  x = re.sub(r'https*://.*', ' ', x)\n",
    "  x = re.sub(r'@[A-Za-z0-9]+', ' ', x)\n",
    "  tokens = word_tokenize(x)\n",
    "  x = ' '.join([w for w in tokens if not w.lower() in stop_words])\n",
    "  x = re.sub(r'[%s]' % re.escape('!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~“…”’'), ' ', x)\n",
    "  x = re.sub(r'\\d+', ' ', x)\n",
    "  x = re.sub(r'\\n+', ' ', x)\n",
    "  x = re.sub(r'\\s{2,}', ' ', x)\n",
    "  return x\n",
    "\n",
    "\n",
    "rdf['clean_text'] = rdf.Content.apply(clean_text)\n",
    "\n",
    "rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.reset_index(drop=False, inplace=True)\n",
    "rdf.rename(columns={'index': 'indno'}, inplace=True)\n",
    "ndf=rdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.clean_text[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"\")\n",
    "user_input2= input('')\n",
    "result = ndf.loc[ndf['indno'] == int(user_input)]\n",
    "result1 = ndf.loc[ndf['indno'] == int(user_input2)]\n",
    "print(result)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = rdf.clean_text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(language=\"english\")\n",
    "topics, probs = topic_model.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model._extract_embeddings(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "doc_embds = topic_model._extract_embeddings(tweets)\n",
    "\n",
    "sim_array = cosine_similarity(doc_embds,doc_embds)\n",
    "similarity_matrix = cosine_similarity(doc_embds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_indices = []\n",
    "for x in range(1900):\n",
    "    for y in range(1900):\n",
    "        if sim_array[x,y] < 0.1:\n",
    "            lower_indices.append((x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lower_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.add(np.where(similarity_matrix < 0.1), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = sim_array[df[0], df[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "sim_array = cosine_similarity(doc_embds, doc_embds)\n",
    "px.imshow(sim_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.imshow(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load(\"doc_sim_matrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(similarity_matrix, 0)\n",
    "\n",
    "similarity_matrix = np.triu(similarity_matrix)\n",
    "\n",
    "most_similar = np.dstack(np.unravel_index(np.argsort(similarity_matrix.ravel())[::-1], similarity_matrix.shape))[0]\n",
    "least_similar = np.dstack(np.unravel_index(np.argsort(similarity_matrix.ravel()), similarity_matrix.shape))[0]\n",
    "\n",
    "\n",
    "doc_ids = ['doc{}'.format(i) for i in range(1900)]\n",
    "ndf = pd.DataFrame(similarity_matrix, index=doc_ids, columns=doc_ids)\n",
    "\n",
    "# Print most similar and least similar documents\n",
    "print('Most similar documents:')\n",
    "for i, j in most_similar[:50]:\n",
    "    print('{} - {} : {}'.format(doc_ids[i], doc_ids[j], similarity_matrix[i,j]))\n",
    "print()\n",
    "\n",
    "print('Least similar documents:')\n",
    "for i, j in least_similar[:50]:\n",
    "    print('{} - {} : {}'.format(doc_ids[i], doc_ids[j], similarity_matrix[i,j]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
